{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "747f0b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f9aabd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1abe523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clear and specific instructions should be provided to guide a model towards the desired output, and longer prompts can provide more clarity and context for the model, leading to more detailed and relevant outputs.\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "You should express what you want a model to do by \\ \n",
    "providing instructions that are as clear and \\ \n",
    "specific as you can possibly make them. \\ \n",
    "This will guide the model towards the desired output, \\ \n",
    "and reduce the chances of receiving irrelevant \\ \n",
    "or incorrect responses. Don't confuse writing a \\ \n",
    "clear prompt with writing a short prompt. \\ \n",
    "In many cases, longer prompts provide more clarity \\ \n",
    "and context for the model, which can lead to \\ \n",
    "more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks \\ \n",
    "into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0bbd254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Depth 1] \n",
      "\n",
      "School - Students, Teachers, Facilities \n",
      "\n",
      "[Depth 2] \n",
      "\n",
      "Students - Classes, Extracurricular Activities, Social Life \n",
      "\n",
      "Teachers - Subjects, Teaching Methods, Professional Development \n",
      "\n",
      "Facilities - Buildings, Equipment, Maintenance\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "topic - School, depth - 2, branch - 3\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "When I give you a topic and the number of depth and branch, you should make a mindmap like this. \\n\n",
    "This is the rule of example's answer. \\n\n",
    "1. word11, word12, word13, word14, word15 are related to word1. \\n\n",
    "2. word21, word22, word23, word24, word25 are related to word11. \\n\n",
    "3. word31, word32, word33, word34, word35 are related to word12. \\n\n",
    "4. word41, word42, word43, word44, word45 are related to word13. \\n\n",
    "5. word51, word52, word53, word54, word55 are related to word14. \\n\n",
    "6. word61, word62, word63, word64, word165 are related to word15. \\n\n",
    "\n",
    "Example: topic - word1, depth - 2, branch - 5 \\n\n",
    "Answer: \\n\n",
    "[Depth 1] \\n\n",
    "word1 - word11, word12, word13, word14, word15 \\n\n",
    "[Depth 2] \\n\n",
    "word11 - word21, word22, word23, word24, word25 \\n\n",
    "word12 - word31, word32, word33, word34, word35 \\n\n",
    "word13 - word41, word42, word43, word44, word45 \\n\n",
    "word14 - word51, word52, word53, word54, word55 \\n\n",
    "word15 - word61, word62, word63, word64, word65 \\n\n",
    "\\n\n",
    "Then, answer this example. \\n\n",
    "Example: {text}\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a41aa06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
